{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归——音乐年代预测\n",
    "## 目录\n",
    "一. 概述：音乐年代预测与回归问题  \n",
    "二. 数据集的加载与展示  \n",
    "三. 特征筛选与预处理  \n",
    "四. 线性回归  \n",
    "五. 多项式回归  \n",
    "六. 岭回归  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一. 概述：音乐年代预测与回归问题\n",
    "## 1. 音乐年代预测问题  \n",
    "- 根据一首音乐的音频特征，推测这首音乐的发行年份。\n",
    "    - 问题的输入：音乐的特征\n",
    "    - 问题的输出：发行年份（是一个实数）\n",
    "- 音乐年代预测问题是一个比较典型的***回归问题***。\n",
    "\n",
    "## 2. 回归问题（regression）  \n",
    "- 和分类问题一样，回归问题也是以数据的特征为输入，以数据的标签为输出。\n",
    "- 回归与分类的区别\n",
    "    - 分类模型的输出是离散的、孤立的类别，比如鸢尾花的种类。\n",
    "    - 回归模型的输出是连续的**数值**，比如这里的年份可以近似看作是连续的。\n",
    "    - 分类问题是提供定性的输出，回归问题是提供定量的输出。\n",
    "- 生活中的回归问题\n",
    "    - 房屋价格预测\n",
    "        - 输入一个房屋的地理位置、面积等特征\n",
    "        - 输出这个房屋的价格\n",
    "    - 气温预测\n",
    "        - 输入某个时刻\n",
    "        - 输出该时刻的气温"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，实验正式开始。\n",
    "- 我们需要首先安装`PrettyTable`模组，它可以帮我们打印好看的表格（如果已安装可忽略）。\n",
    "- 接着我们导入本课程代码所需要的`python`库（不能在后文的代码中自行import）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PrettyTable\n",
      "  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: importlib-metadata in d:\\softwares\\programfiles\\anaconda\\envs\\pytorch\\lib\\site-packages (from PrettyTable) (3.4.0)\n",
      "Requirement already satisfied: wcwidth in d:\\softwares\\programfiles\\anaconda\\envs\\pytorch\\lib\\site-packages (from PrettyTable) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\softwares\\programfiles\\anaconda\\envs\\pytorch\\lib\\site-packages (from importlib-metadata->PrettyTable) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in d:\\softwares\\programfiles\\anaconda\\envs\\pytorch\\lib\\site-packages (from importlib-metadata->PrettyTable) (3.7.4.3)\n",
      "Installing collected packages: PrettyTable\n",
      "Successfully installed PrettyTable-2.1.0\n"
     ]
    }
   ],
   "source": [
    "# 安装PrettyTable模组\n",
    "! pip install PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 导入Python库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from io import StringIO\n",
    "import sys\n",
    "import hdf5_getters  # 和数据集一起放在根目录\n",
    "import prettytable as pt\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print('导入成功！')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二. 数据集的加载与展示\n",
    "## 1. 百万歌曲数据集\n",
    "- 本课程采用的数据集来自于“百万歌曲数据集（Million Song Dataset, MSD）”。\n",
    "    - 百万歌曲数据集包括了1,000,000首当代流行音乐的音频特征和元数据。\n",
    "        - 音频特征是对歌曲的音频的数据描述，包括响度、音色、音调等。\n",
    "        - 歌曲的*元数据*指歌曲名称、演唱者、词曲作者、发行公司、发行年份等信息，它们不能在歌曲的音频中直接体现。\n",
    "- 每首歌用一个`.h5`文件储存其特征，所有的文件在一个目录树中分布。\n",
    "    - `.h5`文件使用`HDF5`格式储存数据，是一种层次化的数据储存格式。\n",
    "    - 本数据集提供了`hdf5_getters.py`模组来读取这种格式的文件（已作为附件提供，也可在数据集官网中下载）。\n",
    "    - 更多关于`HDF5`格式的知识可以参考维基百科：https://en.wikipedia.org/wiki/Hierarchical_Data_Format\n",
    "- 更多关于百万歌曲数据集的介绍、示例、下载等，可以参考官网：http://millionsongdataset.com/\n",
    "    - 原始论文*The Million Song Dataset* http://ismir2011.ismir.net/papers/OS6-1.pdf\n",
    "- 下面，我们展示其中一首歌的特征。\n",
    "    - 我们读取一个数据文件，用数据集提供的`hdf5_getters`模组来获取其中包含的特征。\n",
    "    - 我们首先看一下一个数据文件中包含多少种特征，然后用表格的形式展示出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 2.1 百万歌曲数据集\n",
    "# 2.1.1 一首歌包括多少种特征\n",
    "getter_list = list(filter(lambda x: x[:3] == 'get', hdf5_getters.__dict__.keys()))  # 特征的数量就是getter的种类\n",
    "number_of_features = len(getter_list) \n",
    "print(u'一首歌曲的特征数：', number_of_features)\n",
    "\n",
    "#2.1.2 展示某文件的特征\n",
    "print('文件TRAAABD128F429CF47.h5中的所有特征：')\n",
    "file_path = 'TRAAABD128F429CF47.h5' # 数据集中的一个数据文件\n",
    "file = hdf5_getters.open_h5_file_read(file_path)  # 读取文件\n",
    "\n",
    "table = pt.PrettyTable()\n",
    "table.field_names = [\"序号\", \"特征名\", \"特征类型\", \"值/数组形状\"]\n",
    "for cnt, key in zip(range(1, number_of_features+1), getter_list):\n",
    "    func = hdf5_getters.__dict__[key]\n",
    "    if isinstance(func(file), np.ndarray):  # 如果是数组\n",
    "        table.add_row([cnt, key[4:], str(type(func(file)))[14:-2], func(file).shape]) # 序号，特征名，特征类型，数组形状\n",
    "    else:  # 不是数组\n",
    "        table.add_row([cnt, key[4:], str(type(func(file)))[14:-2], func(file)]) # 序号，特征名，特征类型，特征值\n",
    "print(table)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从上面的结果可以看出：\n",
    "    - 每个样本都有55种特征。\n",
    "    - 从数据类型看，有的特征值是一个实数或字符串，有的特征值是一个array。\n",
    "    - 有的样本的部分特征值缺失了。（比如这里的song_hotttness，即歌曲热度，是nan，意为无效数据。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据集的加载\n",
    "- 在本实验中，我们要使用到百万歌曲数据集中的音频特征和发行年份。我们使用的是*YearPredictionMSD Data Set*。\n",
    "    - 它是百万歌曲数据集的一个子集，包含了其中的音频特征和年份，由加州大学尔湾分校（UCI）的研究人员创建。\n",
    "    - 这个数据集没有重复的样本，也没有缺失的数据。\n",
    "    - 每一个样本都包含90个音频特征。这些特征包括12个平均值和78个协方差。为了时间和空间的效率，我们仅保留前12个音频特征，即12个平均值。\n",
    "    - 来源：https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 数据集的加载\n",
    "################################## Question 1 ########################################\n",
    "# 要求：\n",
    "#   - 加载数据集year_prediction.csv，保存为变量data，类型：DataFrame \n",
    "#   - 将数据集的特征部分另存为变量X，类型：DataFrame\n",
    "#   - 将数据集的标签部分另存为变量Y，类型：Series\n",
    "############################## Start of Your code ####################################\n",
    "\n",
    "\n",
    "\n",
    "############################### End of Your Code #####################################\n",
    "\n",
    "assert X.shape[0] == Y.size  # 检验X和Y的样本数是否一致\n",
    "print('读取成功！')\n",
    "\n",
    "# 查看数据集的行数和列数\n",
    "print('数据集中的样本数：', X.shape[0])\n",
    "print('每个样本的特征数：', X.shape[1])\n",
    "\n",
    "# 查看数据集的前5个样本\n",
    "data.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可见，数据集中有515345个样本，每个样本除了预测目标year以外，有12个特征。\n",
    "- 这些特征包括12个平均值（TimbreAvg1~12）。\n",
    "    - 每一个样本包含每首歌都被分为12个片段（segment），每个片段用一个12维的向量来表示它的音色（timbre）。对每个12维的向量求平均值，那么一首歌可以得到12个平均值。\n",
    "    \n",
    "## 3. 数据集的展示\n",
    "- 我们首先来以10年为一个单位，展示数据集中歌曲年代的分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 每个十年的歌曲数\n",
    "################################## Question 2 ########################################\n",
    "# 要求：\n",
    "#   - 首先根据歌曲年份计算年代，并将歌曲年代作为一个额外的特征decade加入变量data中。\n",
    "#     - 例如一首歌的发行年份是1986，那么它的decade列的数据应为1980\n",
    "#   - 绘制一幅统计图，展示每个十年的歌曲数。\n",
    "# 提示：\n",
    "#   - 计数和绘图可使用seaborn.countplot()\n",
    "############################## Start of Your code ####################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################### End of Your Code #####################################\n",
    "\n",
    "plt.title('Distribution of Release Year',fontsize=20)\n",
    "plt.xlabel('Count of Songs',fontsize=14)\n",
    "plt.ylabel('Decade',fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们的任务，就是使用这些样本进行训练。\n",
    "- 我们想要建立起一个回归模型，即对于一个未知的样本：\n",
    "    - 输入：由12个特征值组成的向量\n",
    "    - 输出：音乐的发行年代year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三. 特征筛选与预处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 特征筛选\n",
    "- 根据第二部分的结果，我们可以发现，在百万歌曲数据集中：\n",
    "    1. 不是所有特征都是数字，能方便地进行数学计算；\n",
    "    2. 不是所有特征都与我们的目标（预测年代）密切相关；\n",
    "- 因此，需要对这些特征进行***特征筛选***，即：保留部分特征作为后续分析的输入。\n",
    "- 我们采用的数据集YearPredictionMSD Data Set，已对百万歌曲数据集进行了数据筛选。\n",
    "    - 只保留了和音色timbre有关的特征，然后进行计算，得到平均值和协方差。\n",
    "    \n",
    "## 2. 特征的数值分布展示\n",
    "- 我们观察一下样本中各维度的数值分布情况。\n",
    "    - 首先看一下各维度的统计数据：平均值、标准差、最小值、25%、50%、75%、最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 为了直观地展现特征的数值分布，下面绘制每个维度的分布直方图\n",
    "    - 每一幅图的横坐标代表值的大小，纵坐标代表频数/分度值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))  # 新建一个12*10的画布\n",
    "fig.suptitle(\"Distribution of features\", fontsize=20)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "# 画12个子图\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(4,3,i+1)\n",
    "    sns.distplot(X.iloc[:,i])  # 调用seaborn中的直方图\n",
    "    plt.xlabel(f'Feature {i+1}', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可见：各个维度的数值范围差异是很大的，为此我们需要进行***特征缩放***。\n",
    "\n",
    "## 3. 特征缩放\n",
    "- 特征缩放：将各项特征的值缩放到相同或相近的大小范围。\n",
    "- 为什么要进行特征缩放？\n",
    "    - 模型在训练时会主要受数值大的特征影响\n",
    "    - 如果不进行特征缩放，回归分析的训练时间会变长\n",
    "    - 我们接下来使用的模型对数据的规模特别敏感，不缩放就很难训练\n",
    "- 特征缩放的方法：\n",
    "    1. ***标准化（Standardization）***：一般指使数据的均值为0，方差为1\n",
    "        - 有时也指将数据的数值范围压缩到一个固定的范围，比如$[0, 1]$\n",
    "    2. ***归一化（Normalization）***：使数据的特征向量缩放到单位长度\n",
    "- 在本次实验中，我们选用`scikit-learn`中内建的特征缩放方法来处理数据\n",
    "    - 可以参考 https://scikit-learn.org/stable/modules/preprocessing.html 中6.3.1-3中的介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3.3 特征缩放\n",
    "# 使用sklearn.preprocessing模组中的方法，对数据进行标准化\n",
    "################################### Question 2 #########################################\n",
    "# 要求：\n",
    "#   - 对X中的数据进行标准化，将缩放后的数据存为X_scaled，类型：DataFrame\n",
    "#     - 使用sklearn.preprocessing中的特征缩放方法\n",
    "# 提示：\n",
    "#   - 参考上文提到的网址，选一个合适的Scaler\n",
    "############################### Start of Your Code #####################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################ End of Your Code ######################################\n",
    "# 展示各特征的统计量\n",
    "X_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))  # 新建一个12*10的画布\n",
    "fig.suptitle(\"Distribution of features\", fontsize=20)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "# 画12个子图\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(4,3,i+1)\n",
    "    sns.distplot(X.iloc[:,i])  # 调用seaborn中的直方图\n",
    "    plt.xlabel(f'Feature {i+1}', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 特征展示\n",
    "- 下面我们尝试直观展示一下不同年代音乐之间的特征差异\n",
    "    - 随机抽取四个特征，做散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 3.4 特征展示\n",
    "X_sample=X.sample(n=4, axis=1)\n",
    "X_sample['decade']=data['decade']\n",
    "X_sample=X_sample.sample(1000)\n",
    "sns.pairplot(data=X_sample, hue='decade', vars=X_sample.columns[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用热力图（heatmap）展现不同年代音乐的特征向量。\n",
    "    - 我们剔除样本过少的20~40年代音乐，然后从每个年代的音乐中取相同数量，对它们的特征向量求平均值。\n",
    "    - 颜色越浅代表这一年代音乐的某一平均特征的值越大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_t = data[data.decade>1940]  # 剔除40年代及以前\n",
    "min_samples = data_t.decade.value_counts().min()\n",
    "decades = data_t.decade.unique()\n",
    "data_sampled = pd.DataFrame(columns=data_t.columns)\n",
    "\n",
    "for decade in decades:\n",
    "    data_sampled = data_sampled.append(data_t[data_t.decade==decade].sample(min_samples))\n",
    "data_sampled.decade = data_sampled.decade.astype(int)\n",
    "\n",
    "labels = [\"{:02d}'s'\".format(l%100) for l in sorted(data_sampled.decade.unique())]\n",
    "fig, ax = plt.subplots(figsize=(12,5)) \n",
    "sns.heatmap(data_sampled.groupby(['decade']).mean(), yticklabels=labels)\n",
    "plt.ylabel(\"Decade\")\n",
    "plt.xlabel(\"Average of features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 数据集划分\n",
    "- 回归问题是一类***监督学习***的问题\n",
    "    - 监督学习需要有训练数据集\n",
    "- 我们把数据集划分为***训练数据集***和***测试数据集***\n",
    "    - 模型仅使用训练集中的数据进行训练\n",
    "    - 训练完成后，然后在测试集中进行测试\n",
    "- 一般来说，需要指定训练集和测试集的比例。\n",
    "    - 本课程采用的数据集推荐的划分是：前463,715个样本为训练集，后51,630个样本为测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 3.5 数据集划分\n",
    "################################### Question 3 #########################################\n",
    "# 要求：\n",
    "#   - 对数据进行数据集划分，要满足前463,715个样本为训练集，后51,630个样本为测试集\n",
    "#   - 将训练集特征、测试集特征分别存为x_train, x_test，类型：DataFrame\n",
    "#   - 将训练集目标、测试集目标分别存为y_train, y_test，类型：Series\n",
    "############################### Start of Your Code #####################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################ End of Your Code ######################################\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四. 线性回归\n",
    "## 1. 线性回归\n",
    "- **回归方程（regression equation）**，又叫**假设（hypothesis）**或**预测函数**。\n",
    "    - 回归方程就是通过学习建立起来的，输入的特征向量与输出的关系式。\n",
    "    - 有了回归方程，将一个未知样本的特征$\\vec x$输入进去，就可得到他的输出值$y$的预测值。\n",
    "    - 当回归方程是一个线性函数时，称为***线性回归***。\n",
    "$$ h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+\\dots+\\theta_nx_n=\\theta^Tx $$\n",
    "\n",
    "## 2. 代价函数\n",
    "- 如何评估模型的好坏\n",
    "    - ***代价函数***：评估真实值与预测值之间的差异\n",
    "    - 在线性回归中，我们常用平方损失（squared loss）来描述误差\n",
    "    $$ J(\\theta)=\\frac{1}{2m}\\sum\\limits_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2,\\quad \\mbox{$m$ 为样本数} $$\n",
    "    - 用矩阵的记号写出来\n",
    "    $$J(\\theta)=\\frac{1}{2m}(X\\theta-y)^T(X\\theta-y)$$\n",
    "    ![loss_function](loss_example.png)\n",
    "- 回归模型的训练过程就是为了得到最好的模型，也就是**让代价函数最小**\n",
    "    - 解析求解（`Sklearn`里的`LinearRegression`）\n",
    "        - 可以通过**最小二乘法**得到回归公式中$\\theta$的解析解\n",
    "        - 只需要将上面的回归公式对$\\theta$求导，令其为0，即可解得$\\theta$的解析解。这个解是：\n",
    "        $$\\theta=(X^TX)^{-1}X^Ty$$\n",
    "        - 上面的这个解叫做**正规方程（normal equation）**\n",
    "    - 解析求解对于大规模的数据有什么问题\n",
    "        - 当样本特征数大的时候，计算$(X^TX)^{-1}$十分困难\n",
    "    - 我们还可以使用梯度下降的方法得到所需的$\\theta$\n",
    "\n",
    "## 3. 梯度下降\n",
    "- ***梯度下降***\n",
    "    - 沿着$J(θ)$的负梯度方向走，我们就能接近其最小值，或者极小值，从而接近更高的预测精度。\n",
    "    - 重复计算下面的公式，直到收敛：\n",
    "    $$\\theta_j = \\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta) \\quad \\mbox{$\\alpha$ 为学习率}$$\n",
    "    - 计算$J(θ)$的梯度，得：\n",
    "    $$\\theta_j = \\theta_j+\\alpha\\frac{1}{m}\\sum\\limits_{i=1}^{m}(y^{(i)}-h_\\theta(x^{(i)}))x_j^{(i)}$$\n",
    "- ***收敛***：\n",
    "    - 这个沿着负梯度向下的过程一直迭代重复，直到$J(θ)$的值基本不变了，就称为收敛。\n",
    "    - 这时候我们就知道达到了极小值。\n",
    "- ***随机梯度下降（Stochastic Gradient Descent）***（`Sklearn`里的`SGDRegressor`）\n",
    "    - 根据上面的公式，每调整一次$\\theta$，都需要把整个训练数据集都过一遍，效率太低了。\n",
    "    - 随机梯度下降就是每次迭代时只任选一个样本进行更新，不再对所有样本都计算一遍并求和。\n",
    "    $$\\begin{align*}\n",
    "& \\mbox{重复直到收敛（Repeat until convergence）:} \\\\\n",
    "& \\quad \\mbox{for $i=1$ to $m$}: \\\\\n",
    "& \\quad \\quad \\theta_j = \\theta_j+\\alpha(y^{(i)}-h_\\theta(x^{(i)}))x_j^{(i)}\n",
    "\\end{align*}$$\n",
    "    - 可能会出现抖动，不一定能获得全局最优\n",
    "- ***学习率（步长）***  \n",
    "    - 梯度下降公式中，梯度前面的系数$\\alpha$就是学习率，又叫步长。\n",
    "    - 学习率标识了沿梯度方向行进的速率，是一个重要的超参数。\n",
    "    - 如果学习率太大，很可能“迈过”最小值。如果太小，则会收敛得很慢。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4 线性回归预测歌曲的年份\n",
    "\n",
    "# 用于保存代价函数的历史记录\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = mystdout = StringIO()\n",
    "\n",
    "# 模型训练\n",
    "#################################### Question 4 #############################################\n",
    "# 要求：\n",
    "#    - 为lin_reg确定合适的参数，并拟合x_train, y_train进行训练\n",
    "#    - 使用sklearn.linear_model.SGDRegressor()\n",
    "#    - 参数verbose应设为1，以遍绘制代价函数的下降\n",
    "################################ Start of Your Code #########################################\n",
    "\n",
    "\n",
    "################################# End of Your Code ##########################################\n",
    "\n",
    "# 得到代价函数的历史记录\n",
    "sys.stdout = old_stdout\n",
    "loss_history = mystdout.getvalue()\n",
    "loss_list = []\n",
    "for line in loss_history.split('\\n'):\n",
    "    if len(line.split(\"loss: \")) == 1:\n",
    "        continue\n",
    "    loss_list.append(float(line.split(\"loss: \")[-1]))\n",
    "\n",
    "print('迭代次数:', len(loss_list))\n",
    "\n",
    "# 代价函数下降的可视化\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(loss_list)), loss_list)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 得到训练好的线性回归模型之后，下面评估其预测结果\n",
    "    - 分别在训练集、测试集上评估模型预测值的准确率和均方误差\n",
    "        - 计算准确率时，不能以完全相等作为相等，应该给定一个范围。\n",
    "        - 本题中，当预测值与真实值的偏差小于等于5时，认为预测准确。\n",
    "            - 譬如，若真实年份为2000年，预测年份为1995~2005之间都算作预测准确。\n",
    "        - ***均方误差（Mean square error, MSE）***也可以作为评价标准\n",
    "    - 然后从训练集、测试集上分别抽取一些样本，直观对比的它们真实值和预测值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Question 5 ########################################\n",
    "# 要求：完成函数evaluate_model()，使其具备下面的功能。\n",
    "#   - 功能：得到一个模型在一个数据集上的准确率和均方差\n",
    "#     - 注：本题中，对某一样本，当预测值与实际值相差不大于5时，认为预测准确。\n",
    "#   - 参数：\n",
    "#     - model：要评估的模型\n",
    "#     - X: 数据集的特征\n",
    "#     - y：数据集的标签\n",
    "#   - 返回值：\n",
    "#     - 返回值1：准确率\n",
    "#     - 返回值2：均方误差\n",
    "# 提示：\n",
    "#   - 准确率的计算可以借助sklearn.metrics.accuracy_score()方法\n",
    "#   - 均方差的计算可以借助sklearn.metrics.mean_squared_error()方法\n",
    "#   - 上面提到的两种方法只是一种可能的实现，并不是一定要用到\n",
    "############################## Start of Your Code #####################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################ End of Your Code #####################################\n",
    "\n",
    "# 训练集准确率和均方差\n",
    "accuracy_rate_lr_train, mse_lr_train = evaluate_model(lin_reg, x_train, y_train)\n",
    "print('模型训练准确率为:', accuracy_rate_lr_train)\n",
    "print('模型训练均方误差为:', mse_lr_train)\n",
    "\n",
    "# 测试集准确率和均方差\n",
    "accuracy_rate_lr_test, mse_lr_test = evaluate_model(lin_reg, x_test, y_test)\n",
    "print('模型测试准确率为:', accuracy_rate_lr_test)\n",
    "print('模型测试均方误差为:', mse_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def barplot(true, pred, yi=None, ym=None):\n",
    "    \"\"\"\n",
    "    用于绘制柱状图以对比真实值和预测值的函数\n",
    "    yi: 纵坐标的下限\n",
    "    ym: 纵坐标的上限\n",
    "    \"\"\"\n",
    "    width=0.3;\n",
    "    x = np.array([x for x in range(1,len(true)+1)]); # 第一个数据序列x轴\n",
    "    x1 = x - width; # 为使其并列，使得第一个x轴序列全部减去条宽度\n",
    "    plt.bar(x1,true,width=width, label='true');\n",
    "    plt.bar(x,pred,width=width, label='predicted');\n",
    "    plt.legend(loc='upper left'); # 设置标签显示在左上角\n",
    "    if yi and ym:\n",
    "        plt.ylim(yi,ym);\n",
    "    plt.show();\n",
    "    \n",
    "    \n",
    "# 针对训练数据集，对比预测值和实际值\n",
    "samples_x_train, samples_y_train = shuffle(x_train, y_train, n_samples=10, random_state=0)  # 从训练集中随机选取10个样本\n",
    "predicted_train = lin_reg.predict(samples_x_train)\n",
    "print('训练集样本的原始标签:\\n', samples_y_train.values)\n",
    "print('训练集样本的预测结果:\\n', predicted_train)\n",
    "barplot(samples_y_train, predicted_train, 1900, 2030)\n",
    "print('-------------------------------------------')\n",
    "\n",
    "# 针对测试数据集，展示预测效果\n",
    "samples_x_test, samples_y_test = shuffle(x_test, y_test, n_samples=10, random_state=0)\n",
    "predicted_test = lin_reg.predict(samples_x_test)\n",
    "print('测试集样本的原始标签:', samples_y_test.values)\n",
    "print('测试集样本的预测结果:', predicted_test)\n",
    "barplot(samples_y_test, predicted_test, 1900, 2030)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比模型对于训练数据集和测试数据集的预测结果\n",
    "- 可以看到，模型对测试集的预测效果往往不如训练集的效果。\n",
    "- 如果训练集训练出来的模型也能很好地预测测试集的数据，那么这个模型的**泛化**能力就好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五. 多项式回归\n",
    "## 1. 多项式回归介绍\n",
    "- **多项式回归**\n",
    "    - 不再使用单纯的线性函数去拟合数据，而是使用一个多项式函数。\n",
    "    - 例如，一个二次多项式：\n",
    "    $$P_2(x)=\\theta^T[1,x_1,x_2,x_1^2,x_2^2]$$\n",
    "    - 会拓展数据集特征空间的维度\n",
    "- 当线性回归效果不好时，即***欠拟合***时，需要尝试多项式回归\n",
    "    - 欠拟合：当模型在训练集中表现不好时，自然更不会在测试数据中表现得好。这种情况就是欠拟合。\n",
    "    \n",
    "## 2. 交互项\n",
    "- 多项式回归中可以增加***交互项***\n",
    "- 什么是交互项\n",
    "    - 例如，在二次多项式$P(x)=\\theta^T[1,x_1,x_2,x_1^2,x_1x_2,x_2^2]$中，$x_1x_2$就是交叉项\n",
    "- 以本课问题为例，如果某一音乐家在某一年代倾向于创作较长的音乐，另一时间段倾向于创作较短的音乐。这种情况下，可以增加创作者这一特征和音乐时长这一特征的交互项，帮助模型拟合\n",
    "    - 我们这里并没有这么做，因为选取的特征并不符合这一特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 使用多项式回归训练模型\n",
    "\n",
    "# 多项式数据准备\n",
    "#################################### Question 6 #############################################\n",
    "# 要求：\n",
    "#   - 将X中的数据转化成三次多项式的数据\n",
    "#   - 再将转化好的数据进行标准化、数据划分，得到poly_x_train, poly_x_test，类型：DataFrame\n",
    "#      - 数据划分的比例仍应该按照Question 3的要求\n",
    "# 提示：\n",
    "#   - 使用sklearn.preprocessing.PolynomialFeatures()进行转化\n",
    "#   - 如果计算机的性能很差，可以只使用二次多项式（一般来说都是可以的）\n",
    "################################ Start of Your Code #########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################# End of Your Code ##########################################\n",
    "print(poly_x_train.shape)\n",
    "print(poly_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 用于保存代价函数的历史记录\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = mystdout = StringIO()\n",
    "\n",
    "# 模型训练\n",
    "#################################### Question 7 #############################################\n",
    "# 要求：\n",
    "#    - 为pol_reg确定合适的参数，并拟合poly_x_train, y_train进行训练\n",
    "#    - 使用sklearn.linear_model.SGDRegressor()\n",
    "#    - 参数verbose应设为1，以遍绘制代价函数的下降\n",
    "################################ Start of Your Code #########################################\n",
    "\n",
    "\n",
    "################################# End of Your Code ##########################################\n",
    "\n",
    "# 得到代价函数的历史记录\n",
    "sys.stdout = old_stdout\n",
    "loss_history = mystdout.getvalue()\n",
    "loss_list = []\n",
    "for line in loss_history.split('\\n'):\n",
    "    if(len(line.split(\"loss: \")) == 1):\n",
    "        continue\n",
    "    loss_list.append(float(line.split(\"loss: \")[-1]))\n",
    "\n",
    "print(len(loss_list))\n",
    "\n",
    "# 代价函数下降的可视化\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(loss_list)), loss_list)\n",
    "plt.xlabel(\"Time in epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 训练集准确率和均方差\n",
    "accuracy_rate_pr_train, mse_pr_train = evaluate_model(pol_reg, poly_x_train, y_train)\n",
    "print('模型训练准确率为:', accuracy_rate_pr_train)\n",
    "print('模型训练均方误差为:', mse_pr_train)\n",
    "\n",
    "# 测试集准确率和均方差\n",
    "accuracy_rate_pr_test, mse_pr_test = evaluate_model(pol_reg, poly_x_test, y_test)\n",
    "print('模型测试准确率为:', accuracy_rate_pr_test)\n",
    "print('模型测试均方误差为:', mse_pr_test)\n",
    "\n",
    "print('-------------------------------------------')\n",
    "\n",
    "# 针对训练数据集，展示预测效果\n",
    "samples_poly_x_train, samples_y_train = shuffle(poly_x_train, y_train, n_samples=10, random_state=0)\n",
    "poly_predicted_train = pol_reg.predict(samples_poly_x_train)\n",
    "print('训练集样本的原始标签:', samples_y_train.values)\n",
    "print('训练集样本的预测结果:', poly_predicted_train)\n",
    "barplot(samples_y_train, poly_predicted_train, 1900, 2030)\n",
    "print('-------------------------------------------')\n",
    "\n",
    "# 针对测试数据集，展示预测效果\n",
    "samples_poly_x_test, samples_y_test = shuffle(poly_x_test, y_test, n_samples=10, random_state=0)\n",
    "poly_predicted_test = pol_reg.predict(samples_poly_x_test)\n",
    "print('测试集样本的原始标签:', samples_y_test.values)\n",
    "print('测试集样本的预测结果:', poly_predicted_test)\n",
    "barplot(samples_y_test, poly_predicted_test, 1900, 2030)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用多项式回归可以解决欠拟合的问题，但又可能带来过拟合\n",
    "    - ***过拟合***：指模型可以非常好地拟合训练数据，预测测试集时却表现很差\n",
    "    \n",
    "### 理解欠拟合与过拟合\n",
    "例如我们想要拟合下面的数据\n",
    "<img src=\"data.png\" width=\"400\" hegiht=\"300\" align=center />\n",
    "- 如果采用线性回归，那么拟合效果显然不好，数据距离拟合曲线较远\n",
    "- 采用二次多项式回归，拟合效果刚刚好\n",
    "- 采用100次多项式回归，虽然貌似拟合几乎每一个数据，但是丢失了信息规律，显然不能很好地预测未知的数据\n",
    "\n",
    "![underfitvsoverfit](under&overfit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 六. 岭回归\n",
    "## 1. 正则化\n",
    "- 正如上面过拟合的例子显示，当模型**复杂度**高（比如参数很多）的时候，很容易出现过拟合。\n",
    "    - 训练集误差很低，测试集表现较差——模型的泛化能力较差。\n",
    "- ***正则化(Regularization)*** 是一种减少**测试**误差的手段。\n",
    "    - 我们试图拉伸函数曲线使之更加平滑\n",
    "    - 为了拉伸曲线，也就要弱化一些高阶项（曲线曲折的罪魁祸首）\n",
    "    - 为此，我们想要降低高阶项的系数$\\theta_i$大小——这叫做**惩罚**\n",
    "- 做法：\n",
    "    - 设模型的代价函数是$L(\\theta)$，而我们的惩罚项是$R(\\theta)$\n",
    "    - 那么，将目标函数写为$J(\\theta)=L(\\theta)+\\alpha R(\\theta)$，再最小化目标函数即可\n",
    "    - 其中$\\alpha$是一个超参数，它决定了正则化惩罚的“力度”。$\\alpha$越大，惩罚“力度”越大。\n",
    "    \n",
    "## 2. 岭回归\n",
    "- ***岭回归***是一种常用的正则化线性回归。\n",
    "    - 使用线性回归的代价函数，而惩罚项$R(\\theta)=\\sum\\limits_{i=1}^{n}\\theta_i^2$\n",
    "    - 也就是目标函数写为：\n",
    "    $$J(\\theta)=L(\\theta)+\\alpha\\sum\\limits_{i=1}^{n}\\theta_i^2$$\n",
    "- 惩罚项的含义是空间中参数点$\\theta$到原点的**欧式距离**的平方\n",
    "    - 因此惩罚的效果是迫使参数点靠近原点，也就是迫使参数变小。\n",
    "- 可以降低模型的复杂度，提高模型的泛化能力，即模型适用于新的数据集的能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 使用岭回归训练模型\n",
    "# 模型训练\n",
    "#################################### Question 8 #############################################\n",
    "# 要求：\n",
    "#   - 确定ridge_reg的参数，使用sklearn.linear_model.Ridge()\n",
    "#   - 用多项式数据，即poly_x_train, y_train来训练ridge_reg\n",
    "################################ Start of Your Code #########################################\n",
    "\n",
    "\n",
    "################################# End of Your Code ##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 预测数据是否会符合我们预期，波动变小呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 训练集准确率和均方差\n",
    "accuracy_rate_rr_train, mse_rr_train = evaluate_model(ridge_reg, poly_x_train, y_train)\n",
    "print('模型训练准确率为:', accuracy_rate_rr_train)\n",
    "print('模型训练均方差为:', mse_rr_train)\n",
    "print('-------------------------------------------')\n",
    "\n",
    "# 测试集准确率和均方差\n",
    "accuracy_rate_rr_test, mse_rr_test = evaluate_model(ridge_reg, poly_x_test, y_test)\n",
    "print('模型测试准确率为:', accuracy_rate_rr_test)\n",
    "print('模型测试均方差为:', mse_rr_test)\n",
    "print('-------------------------------------------')\n",
    "\n",
    "# 针对训练数据集，展示预测效果\n",
    "samples_x_train, samples_y_train = shuffle(poly_x_train, y_train, n_samples=10, random_state=0)\n",
    "predicted_train = ridge_reg.predict(samples_x_train)  # 做预测\n",
    "print('训练集样本的原始标签:', samples_y_train.values)\n",
    "print('训练集样本的预测结果:', predicted_train)\n",
    "barplot(samples_y_train, predicted_train, 1900, 2030)\n",
    "print('-------------------------------------------')\n",
    "\n",
    "# 4.3.2 针对测试数据集，展示预测效果\n",
    "samples_x_test, samples_y_test = shuffle(poly_x_test, y_test, n_samples=10, random_state=0)\n",
    "predicted_test = ridge_reg.predict(samples_x_test)\n",
    "print('测试集样本的原始标签:', samples_y_test.values)\n",
    "print('测试集样本的预测结果:', predicted_test)\n",
    "barplot(samples_y_test, predicted_test, 1900, 2030)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性回归、多项式回归、岭回归模型的表现差异\n",
    "- 对比三个模型对于测试集的预测准确率、均方差\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_present=[['线性回归', '训练集', accuracy_rate_lr_train, mse_lr_train],\n",
    "    ['线性回归', '测试集', accuracy_rate_lr_test, mse_lr_test],\n",
    "    ['多项式回归', '训练集', accuracy_rate_pr_train, mse_pr_train],\n",
    "    ['多项式回归', '测试集', accuracy_rate_pr_test, mse_pr_test],\n",
    "    ['岭回归', '训练集', accuracy_rate_rr_train, mse_rr_train],\n",
    "    ['岭回归', '测试集', accuracy_rate_rr_test, mse_rr_test]]\n",
    "\n",
    "# 使用PrettyTable做一个表格\n",
    "table = pt.PrettyTable()\n",
    "table.field_names = [\"模型\", \"数据集\", \"准确率\", \"均方差\"]\n",
    "for row in data_present:\n",
    "    table.add_row(row)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
